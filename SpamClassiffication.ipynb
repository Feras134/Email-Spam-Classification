{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5ba0ec2-2540-4831-8af9-391d9eeaeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "306384a7-e2ff-4bcf-96c8-5a64d1360cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # keep lowercase alphabetic words\n",
    "    return re.findall(r'\\b[a-z]+\\b', text.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bfccd0c-fc69-4a61-9ec8-5872a258f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    x = []\n",
    "    y = []\n",
    "    for f in glob.glob(os.path.join(directory, \"HAM.*.txt\")):\n",
    "        with open(f, 'r', encoding='latin1') as file:\n",
    "            x.append(file.read())\n",
    "            y.append(0)\n",
    "    for f in glob.glob(os.path.join(directory, \"SPAM.*.txt\")):\n",
    "        with open(f, 'r', encoding='latin1') as file:\n",
    "            x.append(file.read())\n",
    "            y.append(1)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c6dbdea-5dcf-46f4-9e9d-abdf7c367143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_train(x, y):\n",
    "    model = {\n",
    "        'ham_count': 0,\n",
    "        'spam_count': 0,\n",
    "        'ham_fd': defaultdict(int),\n",
    "        'spam_fd': defaultdict(int)\n",
    "    }\n",
    "\n",
    "    for doc, label in zip(x, y):\n",
    "        words = tokenize(doc)\n",
    "        if label == 0:\n",
    "            model['ham_count'] += 1\n",
    "            for word in words:\n",
    "                model['ham_fd'][word] += 1\n",
    "        else:\n",
    "            model['spam_count'] += 1\n",
    "            for word in words:\n",
    "                model['spam_fd'][word] += 1\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95896c85-ed7d-4ece-9948-16c421e7a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_test(docs, model, use_log=False, smoothing=False):\n",
    "    predictions = []\n",
    "    all_words = set(model['ham_fd'].keys()) | set(model['spam_fd'].keys())\n",
    "    vocab_size = len(all_words)\n",
    "    ham_total = sum(model['ham_fd'].values())\n",
    "    spam_total = sum(model['spam_fd'].values())\n",
    "\n",
    "    for doc in docs:\n",
    "        words = tokenize(doc)\n",
    "\n",
    "        if use_log:\n",
    "            ham_prob = math.log(model['ham_count'] / (model['ham_count'] + model['spam_count']))\n",
    "            spam_prob = math.log(model['spam_count'] / (model['ham_count'] + model['spam_count']))\n",
    "        else:\n",
    "            ham_prob = model['ham_count'] / (model['ham_count'] + model['spam_count'])\n",
    "            spam_prob = model['spam_count'] / (model['ham_count'] + model['spam_count'])\n",
    "\n",
    "        for word in words:\n",
    "            ham_freq = model['ham_fd'][word]\n",
    "            spam_freq = model['spam_fd'][word]\n",
    "\n",
    "            if smoothing:\n",
    "                ham_word_prob = (ham_freq + 1) / (ham_total + vocab_size)\n",
    "                spam_word_prob = (spam_freq + 1) / (spam_total + vocab_size)\n",
    "            else:\n",
    "                ham_word_prob = ham_freq / ham_total if ham_freq > 0 else 1e-10\n",
    "                spam_word_prob = spam_freq / spam_total if spam_freq > 0 else 1e-10\n",
    "\n",
    "            if use_log:\n",
    "                ham_prob += math.log(ham_word_prob)\n",
    "                spam_prob += math.log(spam_word_prob)\n",
    "            else:\n",
    "                ham_prob *= ham_word_prob\n",
    "                spam_prob *= spam_word_prob\n",
    "\n",
    "        predictions.append(1 if spam_prob > ham_prob else 0)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6772df3-552a-4fa3-bdb8-bbd78b94bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(y_true, y_pred):\n",
    "    tp = sum((yt == 1 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "    fp = sum((yt == 0 and yp == 1) for yt, yp in zip(y_true, y_pred))\n",
    "    fn = sum((yt == 1 and yp == 0) for yt, yp in zip(y_true, y_pred))\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return 2 * precision * recall / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411784d9-31ba-4db9-a2db-0c74864048ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18457 training emails.\n",
      "Loaded 800 testing emails.\n"
     ]
    }
   ],
   "source": [
    "training_dir = \"./project2/SPAM_training_set\"\n",
    "test_dir = \"./project2/SPAM_test_set\"\n",
    "\n",
    "x_train, y_train = load_data(training_dir)\n",
    "x_test, y_test = load_data(test_dir)\n",
    "\n",
    "print(\"Loaded\", len(x_train), \"training emails.\")\n",
    "print(\"Loaded\", len(x_test), \"testing emails.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ace6406-7ee7-4c8d-b1bb-243651c59853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "model = nb_train(x_train, y_train)\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d6fb256-f641-4112-9d5c-e669ef0c36a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    (False, False),  # No log, No smoothing\n",
    "    (False, True),   # No log, With smoothing\n",
    "    (True, False),   # With log, No smoothing\n",
    "    (True, True)     # With log, With smoothing\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for use_log, smoothing in configs:\n",
    "    y_pred = nb_test(x_test, model, use_log=use_log, smoothing=smoothing)\n",
    "    score = f_score(y_test, y_pred)\n",
    "    results[(use_log, smoothing)] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2954ee41-af11-49f9-a67b-90e44f045d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Log + No Smoothing: F1-Score = 0.6318\n",
      "No Log + Smoothing: F1-Score = 0.6532\n",
      "Log + No Smoothing: F1-Score = 0.9780\n",
      "Log + Smoothing: F1-Score = 0.9699\n"
     ]
    }
   ],
   "source": [
    "for config, score in results.items():\n",
    "    log_str = \"Log\" if config[0] else \"No Log\"\n",
    "    smoothing_str = \"Smoothing\" if config[1] else \"No Smoothing\"\n",
    "    print(f\"{log_str} + {smoothing_str}: F1-Score = {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e667fc-7253-419a-9317-c4c9565a6837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
